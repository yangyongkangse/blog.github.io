---
layout:     post
title:      "Kettle性能调优"
subtitle:   ""
date:       2020-07-30 21:51:34 +0800
updateDate: 2020-08-03 17:39:54 +0800
author:     "YangYongKang"
header-style: text
catalog: true
archive:
    - db
    - kettle
    - 数据迁移
tags:
    - db
    - kettle
    - 数据迁移
---

1. 修改spoon脚本的jvm参数
   * PENTAHO_DI_JAVA_OPTIONS="-Xms1024m -Xmx2048m -XX:MaxPermSize=256m" 具体视配置而定
2. 修改日志输出级别
   * 默认的情况下，kettle输出的是基本日志，如果访问十几万的数据库，那基本日志的输出也会达到5、6百兆，这样严重影响了执行效率，所以修改kettle的日志级别为error级，只输出错误日志即可。
   * Rowlevel日志的性能会严重下降,是Basic的1/10
   * 配置：Action => Run options => Log level => Only error
     
3. 调整提交（Commit）记录数大小进行优化(尽量提高批处理的commit size)
   * 修改“表输出”组件中的“提交记录数量”参数进行优化，Kettle默认Commit数量为：1000，可以根据数据量大小来设置Commitsize：1000~50000。
4. 尽量使用数据库连接池
5. 尽量避免使用update , delete操作，尤其是update,如果可以把update变成先delete, 后insert；
6. 能使用truncate table的时候，就不要使用delete all row这种类似sql合理的分区，如果删除操作是基于某一个分区的，就不要使用delete row这种方式（不管是delete sql还是delete步骤）,直接把分区drop掉，再重新创建.
7. 数据抽取的SQL优化
8. 修改链接属性 --此条提升效果比较明显
   * useServerPrepStmts=false  
   * rewriteBatchedStatements=true  
   * useCompression=true
   ![image.png](/img/db-kettle.png)
